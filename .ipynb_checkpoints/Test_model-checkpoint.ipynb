{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py,os\n",
    "import model_structure\n",
    "import matplotlib as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from progressbar import ProgressBar\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "datadir = '/mnt/1a18a49e-9a31-4dbf-accd-3fb8abbfab2d/brain_atac/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(inputs,filter_num,filter_size,dilation,stride = 1,padding = 'same',initilizer = 'glorot_normal'):\n",
    "    conv_l = tf.keras.layers.Conv1D(filters = filter_num,\n",
    "                                    kernel_size = filter_size,\n",
    "                                    strides = stride,\n",
    "                                    padding = padding,\n",
    "                                    dilation_rate = dilation,\n",
    "                                    kernel_initializer = initilizer\n",
    "                                    )(inputs)\n",
    "    conv_l = tf.keras.layers.BatchNormalization()(conv_l)\n",
    "    conv_l = tf.keras.layers.Activation('relu')(conv_l)\n",
    "    return conv_l\n",
    "\n",
    "def residual_block(inputs,filter_num,filter_size,dilation,activation = 'relu'):\n",
    "        #batch_norm+relu+conv+baatch+relu+conv+residual\n",
    "        rb_bn1 = tf.keras.layers.BatchNormalization()(inputs)\n",
    "        rb_ac1 = tf.keras.layers.Activation(activation)(rb_bn1)\n",
    "        rb_conv1 = conv_layer(rb_ac1,filter_num,filter_size,dilation)\n",
    "        rb_bn2 = tf.keras.layers.BatchNormalization()(rb_conv1)\n",
    "        rb_ac2 = tf.keras.layers.Activation(activation)(rb_bn2)\n",
    "        rb_conv2 = conv_layer(rb_ac2,filter_num,filter_size,dilation)\n",
    "        residual_sum = tf.keras.layers.add([inputs,rb_conv2])\n",
    "        return residual_sum\n",
    "    \n",
    "def filter_dataset(sequence,target,limit):\n",
    "    pbar = ProgressBar()\n",
    "    del_list = []\n",
    "    for i in pbar(range(0,len(target))):\n",
    "        if any(y > limit for y in target[i]):\n",
    "            next\n",
    "        else:\n",
    "            del_list.append(i)\n",
    "    print(len(del_list))\n",
    "    filtered_seq = np.delete(sequence,del_list,0)\n",
    "    filtered_target= np.delete(target,del_list,0)\n",
    "   \n",
    "    return filtered_seq,filtered_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 output for basic, 21 for major, \n",
    "f = h5py.File(datadir+'/output_basic.h5','r')\n",
    "x_test = f['test_seq']\n",
    "y_test = f['test_label']\n",
    "x_train = f['train_seq']\n",
    "y_train = f['train_label']\n",
    "x_valid = f['valid_seq']\n",
    "y_valid = f['valid_label']\n",
    "save_model = datadir+'/model/filtered_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n",
      "  2% |#                                                                       |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24098\n"
     ]
    }
   ],
   "source": [
    "#f_x_train,f_y_train= filter_dataset(x_train,y_train)\n",
    "f_x_test,f_y_test= filter_dataset(x_test,y_test,0.03)\n",
    "f_x_valid,f_y_valid= filter_dataset(x_valid,y_valid,0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.63679860e-03 -2.21185156e-04  1.87642905e-04  9.55106057e-04\n",
      "   1.13838499e-04]\n",
      " [-2.21185156e-04  1.26291172e-03  5.40255112e-04 -1.76369522e-04\n",
      "   6.39951047e-04]\n",
      " [ 1.87642905e-04  5.40255112e-04  1.23710382e-03  9.38927734e-05\n",
      "   3.54222747e-04]\n",
      " [ 9.55106057e-04 -1.76369522e-04  9.38927734e-05  2.31183815e-03\n",
      "   6.81315141e-05]\n",
      " [ 1.13838499e-04  6.39951047e-04  3.54222747e-04  6.81315141e-05\n",
      "   7.13317327e-04]]\n"
     ]
    }
   ],
   "source": [
    "cov_matrix = np.cov(f_y_valid,rowvar = False)\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = h5py.File(datadir+'/major_filtered.h5','w')\n",
    "output.create_dataset('test_seq', data=f_x_test, dtype='float32', compression=\"gzip\")\n",
    "output.create_dataset('test_label', data=f_y_test, dtype='float32', compression=\"gzip\")\n",
    "output.create_dataset('train_seq', data=f_x_train, dtype='float32', compression=\"gzip\")\n",
    "output.create_dataset('train_label', data=f_y_train, dtype='float32', compression=\"gzip\")\n",
    "output.create_dataset('valid_seq', data=f_x_valid, dtype='float32', compression=\"gzip\")\n",
    "output.create_dataset('valid_label', data=f_y_valid, dtype='float32', compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20359, 4999, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 4999, 4)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 4999, 32)          672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 4999, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4999, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 4999, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 4999, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 4999, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 4999, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 4999, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 4999, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 2499, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 2499, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 2499, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 2499, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 2499, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 2499, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 2499, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 2499, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 2499, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 2499, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 1249, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 21)                1071      \n",
      "=================================================================\n",
      "Total params: 119,703\n",
      "Trainable params: 119,319\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (4999,4))\n",
    "\n",
    "\n",
    "conv_1 = conv_layer(inputs,32,5,1)\n",
    "conv_2 = conv_layer(conv_1,32,5,1)\n",
    "conv_3 = conv_layer(conv_2,32,5,1)\n",
    "mp_1 = tf.keras.layers.MaxPool1D()(conv_3)\n",
    "\n",
    "conv_4 = conv_layer(mp_1,32,5,1)\n",
    "conv_5 = conv_layer(conv_4,32,5,1)\n",
    "conv_6 = conv_layer(conv_5,32,5,1)\n",
    "mp_2 = tf.keras.layers.MaxPool1D()(conv_6)\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(128)(mp_2)\n",
    "#flat = tf.keras.layers.Flatten()(mp_2)\n",
    "\n",
    "dense_1 = tf.keras.layers.Dense(50,activation = 'relu',kernel_initializer='glorot_normal')(lstm)\n",
    "dense_2 = tf.keras.layers.Dense(50,activation = 'relu',kernel_initializer='glorot_normal')(dense_1)\n",
    "outputs = tf.keras.layers.Dense(21,activation = 'relu',kernel_initializer='glorot_normal')(dense_2)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(inputs = inputs,outputs = outputs,\n",
    "                optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                             min_delta=0, \n",
    "                                             patience=20, \n",
    "                                             verbose=1, \n",
    "                                             mode='min', \n",
    "                                             baseline=None, restore_best_weights=True)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                 factor=0.5,\n",
    "                                                 patience=5, \n",
    "                                                 min_lr=1e-7,\n",
    "                                                 mode='min',\n",
    "                                                 verbose=1)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(save_model, \n",
    "                                                monitor='val_loss', \n",
    "                                                verbose=1, \n",
    "                                                save_best_only=True, \n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 381520 samples, validate on 20359 samples\n",
      "Epoch 1/200\n",
      "381504/381520 [============================>.] - ETA: 0s - loss: 7.6149e-04 - mae: 0.0149\n",
      "Epoch 00001: val_loss improved from inf to 0.00064, saving model to /mnt/1a18a49e-9a31-4dbf-accd-3fb8abbfab2d/brain_atac/notebooks/../data/model/filtered_model.h5\n",
      "381520/381520 [==============================] - 553s 1ms/sample - loss: 7.6147e-04 - mae: 0.0149 - val_loss: 6.4435e-04 - val_mae: 0.0147\n",
      "Epoch 2/200\n",
      "381504/381520 [============================>.] - ETA: 0s - loss: 7.2259e-04 - mae: 0.0149\n",
      "Epoch 00002: val_loss improved from 0.00064 to 0.00063, saving model to /mnt/1a18a49e-9a31-4dbf-accd-3fb8abbfab2d/brain_atac/notebooks/../data/model/filtered_model.h5\n",
      "381520/381520 [==============================] - 555s 1ms/sample - loss: 7.2260e-04 - mae: 0.0149 - val_loss: 6.3457e-04 - val_mae: 0.0143\n",
      "Epoch 3/200\n",
      "381504/381520 [============================>.] - ETA: 0s - loss: 7.1986e-04 - mae: 0.0149\n",
      "Epoch 00003: val_loss did not improve from 0.00063\n",
      "381520/381520 [==============================] - 557s 1ms/sample - loss: 7.1984e-04 - mae: 0.0149 - val_loss: 6.3674e-04 - val_mae: 0.0145\n",
      "Epoch 4/200\n",
      "381504/381520 [============================>.] - ETA: 0s - loss: 7.1993e-04 - mae: 0.0149\n",
      "Epoch 00004: val_loss did not improve from 0.00063\n",
      "381520/381520 [==============================] - 555s 1ms/sample - loss: 7.1992e-04 - mae: 0.0149 - val_loss: 6.4136e-04 - val_mae: 0.0148\n",
      "Epoch 5/200\n",
      "381504/381520 [============================>.] - ETA: 0s - loss: 7.1984e-04 - mae: 0.0149\n",
      "Epoch 00005: val_loss improved from 0.00063 to 0.00063, saving model to /mnt/1a18a49e-9a31-4dbf-accd-3fb8abbfab2d/brain_atac/notebooks/../data/model/filtered_model.h5\n",
      "381520/381520 [==============================] - 554s 1ms/sample - loss: 7.1984e-04 - mae: 0.0149 - val_loss: 6.3084e-04 - val_mae: 0.0139\n",
      "Epoch 6/200\n",
      "381504/381520 [============================>.] - ETA: 0s - loss: 7.1993e-04 - mae: 0.0149\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00063\n",
      "381520/381520 [==============================] - 556s 1ms/sample - loss: 7.1991e-04 - mae: 0.0149 - val_loss: 6.4005e-04 - val_mae: 0.0148\n",
      "Epoch 7/200\n",
      "381504/381520 [============================>.] - ETA: 0s - loss: 7.1928e-04 - mae: 0.0149\n",
      "Epoch 00007: val_loss did not improve from 0.00063\n",
      "381520/381520 [==============================] - 553s 1ms/sample - loss: 7.1928e-04 - mae: 0.0149 - val_loss: 6.3489e-04 - val_mae: 0.0145\n",
      "Epoch 8/200\n",
      "381504/381520 [============================>.] - ETA: 0s - loss: 7.1925e-04 - mae: 0.0149\n",
      "Epoch 00008: val_loss did not improve from 0.00063\n",
      "381520/381520 [==============================] - 554s 1ms/sample - loss: 7.1924e-04 - mae: 0.0149 - val_loss: 6.3676e-04 - val_mae: 0.0145\n",
      "Epoch 9/200\n",
      "381504/381520 [============================>.] - ETA: 0s - loss: 7.1928e-04 - mae: 0.0149\n",
      "Epoch 00009: val_loss did not improve from 0.00063\n",
      "381520/381520 [==============================] - 552s 1ms/sample - loss: 7.1927e-04 - mae: 0.0149 - val_loss: 6.3729e-04 - val_mae: 0.0146\n",
      "Epoch 10/200\n",
      "381504/381520 [============================>.] - ETA: 0s - loss: 7.1926e-04 - mae: 0.0149\n",
      "Epoch 00010: val_loss did not improve from 0.00063\n",
      "381520/381520 [==============================] - 553s 1ms/sample - loss: 7.1925e-04 - mae: 0.0149 - val_loss: 6.3701e-04 - val_mae: 0.0145\n",
      "Epoch 11/200\n",
      "381504/381520 [============================>.] - ETA: 0s - loss: 7.1932e-04 - mae: 0.0149\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00063\n",
      "381520/381520 [==============================] - 553s 1ms/sample - loss: 7.1931e-04 - mae: 0.0149 - val_loss: 6.3351e-04 - val_mae: 0.0143\n",
      "Epoch 12/200\n",
      "331584/381520 [=========================>....] - ETA: 1:11 - loss: 7.1698e-04 - mae: 0.0149WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,lr\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-6c05be3fd18a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf_x_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_y_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                     )\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training = model.fit(f_x_train,f_y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size = 64,\n",
    "                    callbacks = [earlystop,reduce_lr,checkpoint], \n",
    "                    validation_data = (f_x_valid,f_y_valid)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(datadir+'/model/filtered_model.h5')\n",
    "y_pred = model.predict(f_x_test[()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59029084, 0.9951866 , 0.87316   , 0.74109536, 0.93533593],\n",
       "       [0.5378398 , 0.97819597, 0.79155314, 0.6728945 , 0.8759048 ],\n",
       "       [0.170773  , 0.85963535, 0.3081839 , 0.19543484, 0.4607337 ],\n",
       "       ...,\n",
       "       [0.1599878 , 0.75674427, 0.25005984, 0.25322568, 0.55076116],\n",
       "       [0.6152369 , 0.9941505 , 0.8963051 , 0.74880475, 0.9346398 ],\n",
       "       [0.55563825, 0.9669058 , 0.8370737 , 0.7037844 , 0.8618056 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5dadb56780>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(f_y_test[:,1],y_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have 3 dimensions, but got array with shape (38134, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d6611084764b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid_bool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   def predict(self,\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     return self._model_iteration(\n\u001b[1;32m    455\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         sample_weight=sample_weight, steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    563\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have 3 dimensions, but got array with shape (38134, 5)"
     ]
    }
   ],
   "source": [
    "model.evaluate(y_pred,[y_valid,y_valid_bool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
